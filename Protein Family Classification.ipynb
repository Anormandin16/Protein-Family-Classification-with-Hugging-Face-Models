{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up baseline model...\n",
      "Training baseline model (frozen ProtBERT)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Anorm\\anaconda3\\envs\\crystal\\lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Users\\Anorm\\Downloads\\models\\baseline exists and is not empty.\n",
      "\n",
      "  | Name           | Type                  | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | embedder       | BertGenerationEncoder | 418 M  | eval \n",
      "1 | model          | Linear                | 25.6 K | train\n",
      "2 | criterion      | CrossEntropyLoss      | 0      | train\n",
      "3 | val_accuracy   | MulticlassAccuracy    | 0      | train\n",
      "4 | train_accuracy | MulticlassAccuracy    | 0      | train\n",
      "5 | val_f1         | MulticlassF1Score     | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "25.6 K    Trainable params\n",
      "418 M     Non-trainable params\n",
      "418 M     Total params\n",
      "1,675.620 Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "548       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anorm\\anaconda3\\envs\\crystal\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2082/2082 [35:45<00:00,  0.97it/s, v_num=17]     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anorm\\anaconda3\\envs\\crystal\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2082/2082 [14:52<00:00,  2.33it/s, v_num=0, train_acc=0.333, val_acc=0.162, val_f1=0.162]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 3.122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 2082/2082 [14:43<00:00,  2.36it/s, v_num=0, train_acc=0.000, val_acc=0.162, val_f1=0.162] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.055 >= min_delta = 0.0. New best score: 3.067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 2082/2082 [18:04<00:00,  1.92it/s, v_num=0, train_acc=0.000, val_acc=0.0887, val_f1=0.0887]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.034 >= min_delta = 0.0. New best score: 3.033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 2082/2082 [37:30<00:00,  0.93it/s, v_num=0, train_acc=0.333, val_acc=0.102, val_f1=0.102]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.023 >= min_delta = 0.0. New best score: 3.010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 2082/2082 [24:23<00:00,  1.42it/s, v_num=0, train_acc=0.000, val_acc=0.153, val_f1=0.153] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.017 >= min_delta = 0.0. New best score: 2.993\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 2082/2082 [24:23<00:00,  1.42it/s, v_num=0, train_acc=0.000, val_acc=0.153, val_f1=0.153]\n",
      "Baseline model saved at: C:\\Users\\Anorm\\Downloads\\models\\baseline\\baseline-epoch=01-val_acc=0.1622.ckpt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchmetrics\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from transformers import BertTokenizer, BertGenerationEncoder\n",
    "from lightning import LightningModule, LightningDataModule, Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from torch.utils.data import DataLoader\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "class ProteinClassifier(LightningModule):\n",
    "    def __init__(self, n_classes=25):\n",
    "        super().__init__()\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "        self.embedder = BertGenerationEncoder.from_pretrained(\"Rostlab/prot_bert\")\n",
    "        dmodel = 1024\n",
    "        self.model = nn.Linear(dmodel, n_classes)  # Classification head\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.val_accuracy = torchmetrics.classification.Accuracy(task=\"multiclass\",\n",
    "                                                                 num_classes=n_classes)\n",
    "        self.train_accuracy = torchmetrics.classification.Accuracy(task=\"multiclass\",\n",
    "                                                                   num_classes=n_classes)\n",
    "        self.val_f1 = torchmetrics.classification.F1Score(task=\"multiclass\", num_classes=n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lengths = torch.tensor([len(i) for i in x]).to(self.device)\n",
    "        ids = self.tokenizer(x, add_special_tokens=True, padding=\"longest\")\n",
    "        input_ids = torch.tensor(ids['input_ids']).to(self.device)\n",
    "        attention_mask = torch.tensor(ids['attention_mask']).to(self.device).to(self.dtype)\n",
    "        with torch.no_grad():\n",
    "            embeddings = self.embedder(input_ids=input_ids,\n",
    "                                       attention_mask=attention_mask).last_hidden_state\n",
    "        embeddings = embeddings.sum(dim=1) / lengths.view(-1, 1)\n",
    "        logits = self.model(embeddings)\n",
    "        return logits\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch  # Directly unpack the collated batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.train_accuracy(preds, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", self.train_accuracy, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch  # Directly unpack the collated batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_accuracy(preds, y)\n",
    "        self.val_f1(preds, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\", self.val_accuracy, prog_bar=True)\n",
    "        self.log(\"val_f1\", self.val_f1, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=5e-5)\n",
    "\n",
    "\n",
    "class PAFDatamodule(LightningDataModule):\n",
    "    def __init__(self, root_path, batch_size):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.root = root_path\n",
    "        self.classes = pickle.load(open(f\"{root_path}/selected_families.pkl\", \"rb\"))\n",
    "    \n",
    "    def encode_classes(self, y):\n",
    "        cls2idx = dict(zip(self.classes, range(len(self.classes))))\n",
    "        return [cls2idx[i] for i in y]\n",
    "    \n",
    "    def get_dataset(self, part, with_target=True):\n",
    "        file_path = f\"{self.root}/{part}_data.csv\"\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Replace rare amino acids (X, U, B, O, Z) with 'X'\n",
    "        sequences = df.loc[:, \"sequence\"].values\n",
    "        sequences = [re.sub(r'[UBOZ]', 'X', seq) for seq in sequences]\n",
    "        \n",
    "        x = sequences\n",
    "        \n",
    "        if with_target:\n",
    "            y = df.loc[:, \"family_id\"].values\n",
    "            y = torch.tensor(self.encode_classes(y))\n",
    "            return list(zip(x, y))\n",
    "        else:\n",
    "            # For test data without labels\n",
    "            sequence_names = df.loc[:, \"sequence_name\"].values\n",
    "            return list(zip(x, sequence_names))\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        data = self.get_dataset(\"train\")\n",
    "        return DataLoader(data, batch_size=self.batch_size, shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        data = self.get_dataset(\"val\")\n",
    "        return DataLoader(data, batch_size=self.batch_size, shuffle=False)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        data = self.get_dataset(\"test\", with_target=False)\n",
    "        return DataLoader(data, batch_size=self.batch_size, shuffle=False)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        data = self.get_dataset(\"test\", with_target=False)\n",
    "        return DataLoader(data, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set parameters\n",
    "    n_classes = 25\n",
    "    data_root = \"datafiles\"\n",
    "    \n",
    "    # Create directories for saving models\n",
    "    os.makedirs(\"models/baseline\", exist_ok=True)\n",
    "    os.makedirs(\"models/finetuned\", exist_ok=True)\n",
    "    \n",
    "    # Initialize data module\n",
    "    datamodule = PAFDatamodule(data_root, batch_size=16)\n",
    "    \n",
    "    # PART 1: Baseline model (frozen ProtBERT)\n",
    "    print(\"Setting up baseline model...\")\n",
    "    baseline_model = ProteinClassifier(n_classes=n_classes)\n",
    "    \n",
    "    # Freeze the embedder for baseline model\n",
    "    for param in baseline_model.embedder.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Define callbacks for baseline model\n",
    "    baseline_checkpoint = ModelCheckpoint(\n",
    "        dirpath=\"models/baseline/\",\n",
    "        filename=\"baseline-{epoch:02d}-{val_acc:.4f}\",\n",
    "        monitor=\"val_acc\",\n",
    "        mode=\"max\",\n",
    "        save_top_k=1\n",
    "    )\n",
    "    \n",
    "    early_stop = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.00,\n",
    "        patience=3,\n",
    "        verbose=True,\n",
    "        mode=\"min\"\n",
    "    )\n",
    "    \n",
    "    # Set up the TensorBoard logger\n",
    "    logger = TensorBoardLogger(\"tb_logs\", name=\"protein_classifier\")\n",
    "    \n",
    "    # Train baseline model\n",
    "    print(\"Training baseline model (frozen ProtBERT)...\")\n",
    "    baseline_trainer = Trainer(\n",
    "        max_epochs=5,\n",
    "        callbacks=[baseline_checkpoint, early_stop],\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "        gradient_clip_val=1.0,\n",
    "        check_val_every_n_epoch=1,\n",
    "        logger=logger  \n",
    "    )\n",
    "    \n",
    "    baseline_trainer.fit(model=baseline_model, datamodule=datamodule)\n",
    "    \n",
    "    # Save the final baseline model\n",
    "    baseline_trainer.save_checkpoint(\"models/baseline/final_baseline_model.ckpt\")\n",
    "    \n",
    "    # Save best model path for reference\n",
    "    with open(\"models/baseline/best_model_path.txt\", \"w\") as f:\n",
    "        f.write(baseline_checkpoint.best_model_path)\n",
    "    \n",
    "    print(f\"Baseline model saved at: {baseline_checkpoint.best_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up fine-tuned model...\n",
      "Training fine-tuned model (unfrozen ProtBERT)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name           | Type                  | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | embedder       | BertGenerationEncoder | 418 M  | eval \n",
      "1 | model          | Linear                | 25.6 K | train\n",
      "2 | criterion      | CrossEntropyLoss      | 0      | train\n",
      "3 | val_accuracy   | MulticlassAccuracy    | 0      | train\n",
      "4 | train_accuracy | MulticlassAccuracy    | 0      | train\n",
      "5 | val_f1         | MulticlassF1Score     | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "418 M     Trainable params\n",
      "0         Non-trainable params\n",
      "418 M     Total params\n",
      "1,675.620 Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "548       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anorm\\anaconda3\\envs\\crystal\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anorm\\anaconda3\\envs\\crystal\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 2082/2082 [15:16<00:00,  2.27it/s, v_num=19, train_acc=0.000, val_acc=0.0718, val_f1=0.0718]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 2082/2082 [15:16<00:00,  2.27it/s, v_num=19, train_acc=0.000, val_acc=0.0718, val_f1=0.0718]\n",
      "Fine-tuned model saved at: C:\\Users\\Anorm\\Downloads\\models\\finetuned\\finetuned-epoch=00-val_f1=0.1622.ckpt\n"
     ]
    }
   ],
   "source": [
    "# PART 2: Fine-tuned model (unfreeze ProtBERT and fine-tune)\n",
    "print(\"Setting up fine-tuned model...\")\n",
    "finetuned_model = ProteinClassifier(n_classes=n_classes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Define callbacks for finetuned model\n",
    "finetuned_checkpoint = ModelCheckpoint(\n",
    "    dirpath=\"models/finetuned/\",\n",
    "    filename=\"finetuned-{epoch:02d}-{val_f1:.4f}\",\n",
    "    monitor=\"val_f1\",\n",
    "    mode=\"max\",\n",
    "    save_top_k=1\n",
    "    )\n",
    "    \n",
    "    # Train finetuned model\n",
    "print(\"Training fine-tuned model (unfrozen ProtBERT)...\")\n",
    "finetuned_trainer = Trainer(\n",
    "    max_epochs=2,\n",
    "    callbacks=[finetuned_checkpoint, early_stop],\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    gradient_clip_val=1.0\n",
    "    )\n",
    "    \n",
    "finetuned_trainer.fit(model=finetuned_model, datamodule=datamodule)\n",
    "    \n",
    "    # Save the final finetuned model\n",
    "finetuned_trainer.save_checkpoint(\"models/finetuned/final_finetuned_model.ckpt\")\n",
    "    \n",
    "    # Save best model path\n",
    "with open(\"models/finetuned/best_model_path.txt\", \"w\") as f:\n",
    "    f.write(finetuned_checkpoint.best_model_path)\n",
    "    \n",
    "print(f\"Fine-tuned model saved at: {finetuned_checkpoint.best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions using model: C:\\Users\\Anorm\\Downloads\\models\\baseline\\baseline-epoch=01-val_acc=0.1622.ckpt\n",
      "Processing batch 1/131\n",
      "Processing batch 2/131\n",
      "Processing batch 3/131\n",
      "Processing batch 4/131\n",
      "Processing batch 5/131\n",
      "Processing batch 6/131\n",
      "Processing batch 7/131\n",
      "Processing batch 8/131\n",
      "Processing batch 9/131\n",
      "Processing batch 10/131\n",
      "Processing batch 11/131\n",
      "Processing batch 12/131\n",
      "Processing batch 13/131\n",
      "Processing batch 14/131\n",
      "Processing batch 15/131\n",
      "Processing batch 16/131\n",
      "Processing batch 17/131\n",
      "Processing batch 18/131\n",
      "Processing batch 19/131\n",
      "Processing batch 20/131\n",
      "Processing batch 21/131\n",
      "Processing batch 22/131\n",
      "Processing batch 23/131\n",
      "Processing batch 24/131\n",
      "Processing batch 25/131\n",
      "Processing batch 26/131\n",
      "Processing batch 27/131\n",
      "Processing batch 28/131\n",
      "Processing batch 29/131\n",
      "Processing batch 30/131\n",
      "Processing batch 31/131\n",
      "Processing batch 32/131\n",
      "Processing batch 33/131\n",
      "Processing batch 34/131\n",
      "Processing batch 35/131\n",
      "Processing batch 36/131\n",
      "Processing batch 37/131\n",
      "Processing batch 38/131\n",
      "Processing batch 39/131\n",
      "Processing batch 40/131\n",
      "Processing batch 41/131\n",
      "Processing batch 42/131\n",
      "Processing batch 43/131\n",
      "Processing batch 44/131\n",
      "Processing batch 45/131\n",
      "Processing batch 46/131\n",
      "Processing batch 47/131\n",
      "Processing batch 48/131\n",
      "Processing batch 49/131\n",
      "Processing batch 50/131\n",
      "Processing batch 51/131\n",
      "Processing batch 52/131\n",
      "Processing batch 53/131\n",
      "Processing batch 54/131\n",
      "Processing batch 55/131\n",
      "Processing batch 56/131\n",
      "Processing batch 57/131\n",
      "Processing batch 58/131\n",
      "Processing batch 59/131\n",
      "Processing batch 60/131\n",
      "Processing batch 61/131\n",
      "Processing batch 62/131\n",
      "Processing batch 63/131\n",
      "Processing batch 64/131\n",
      "Processing batch 65/131\n",
      "Processing batch 66/131\n",
      "Processing batch 67/131\n",
      "Processing batch 68/131\n",
      "Processing batch 69/131\n",
      "Processing batch 70/131\n",
      "Processing batch 71/131\n",
      "Processing batch 72/131\n",
      "Processing batch 73/131\n",
      "Processing batch 74/131\n",
      "Processing batch 75/131\n",
      "Processing batch 76/131\n",
      "Processing batch 77/131\n",
      "Processing batch 78/131\n",
      "Processing batch 79/131\n",
      "Processing batch 80/131\n",
      "Processing batch 81/131\n",
      "Processing batch 82/131\n",
      "Processing batch 83/131\n",
      "Processing batch 84/131\n",
      "Processing batch 85/131\n",
      "Processing batch 86/131\n",
      "Processing batch 87/131\n",
      "Processing batch 88/131\n",
      "Processing batch 89/131\n",
      "Processing batch 90/131\n",
      "Processing batch 91/131\n",
      "Processing batch 92/131\n",
      "Processing batch 93/131\n",
      "Processing batch 94/131\n",
      "Processing batch 95/131\n",
      "Processing batch 96/131\n",
      "Processing batch 97/131\n",
      "Processing batch 98/131\n",
      "Processing batch 99/131\n",
      "Processing batch 100/131\n",
      "Processing batch 101/131\n",
      "Processing batch 102/131\n",
      "Processing batch 103/131\n",
      "Processing batch 104/131\n",
      "Processing batch 105/131\n",
      "Processing batch 106/131\n",
      "Processing batch 107/131\n",
      "Processing batch 108/131\n",
      "Processing batch 109/131\n",
      "Processing batch 110/131\n",
      "Processing batch 111/131\n",
      "Processing batch 112/131\n",
      "Processing batch 113/131\n",
      "Processing batch 114/131\n",
      "Processing batch 115/131\n",
      "Processing batch 116/131\n",
      "Processing batch 117/131\n",
      "Processing batch 118/131\n",
      "Processing batch 119/131\n",
      "Processing batch 120/131\n",
      "Processing batch 121/131\n",
      "Processing batch 122/131\n",
      "Processing batch 123/131\n",
      "Processing batch 124/131\n",
      "Processing batch 125/131\n",
      "Processing batch 126/131\n",
      "Processing batch 127/131\n",
      "Processing batch 128/131\n",
      "Processing batch 129/131\n",
      "Processing batch 130/131\n",
      "Processing batch 131/131\n",
      "Submission file created at baseline_submission.csv with 4163 predictions\n",
      "Generating predictions using model: C:\\Users\\Anorm\\Downloads\\models\\finetuned\\finetuned-epoch=00-val_f1=0.1622.ckpt\n",
      "Processing batch 1/131\n",
      "Processing batch 2/131\n",
      "Processing batch 3/131\n",
      "Processing batch 4/131\n",
      "Processing batch 5/131\n",
      "Processing batch 6/131\n",
      "Processing batch 7/131\n",
      "Processing batch 8/131\n",
      "Processing batch 9/131\n",
      "Processing batch 10/131\n",
      "Processing batch 11/131\n",
      "Processing batch 12/131\n",
      "Processing batch 13/131\n",
      "Processing batch 14/131\n",
      "Processing batch 15/131\n",
      "Processing batch 16/131\n",
      "Processing batch 17/131\n",
      "Processing batch 18/131\n",
      "Processing batch 19/131\n",
      "Processing batch 20/131\n",
      "Processing batch 21/131\n",
      "Processing batch 22/131\n",
      "Processing batch 23/131\n",
      "Processing batch 24/131\n",
      "Processing batch 25/131\n",
      "Processing batch 26/131\n",
      "Processing batch 27/131\n",
      "Processing batch 28/131\n",
      "Processing batch 29/131\n",
      "Processing batch 30/131\n",
      "Processing batch 31/131\n",
      "Processing batch 32/131\n",
      "Processing batch 33/131\n",
      "Processing batch 34/131\n",
      "Processing batch 35/131\n",
      "Processing batch 36/131\n",
      "Processing batch 37/131\n",
      "Processing batch 38/131\n",
      "Processing batch 39/131\n",
      "Processing batch 40/131\n",
      "Processing batch 41/131\n",
      "Processing batch 42/131\n",
      "Processing batch 43/131\n",
      "Processing batch 44/131\n",
      "Processing batch 45/131\n",
      "Processing batch 46/131\n",
      "Processing batch 47/131\n",
      "Processing batch 48/131\n",
      "Processing batch 49/131\n",
      "Processing batch 50/131\n",
      "Processing batch 51/131\n",
      "Processing batch 52/131\n",
      "Processing batch 53/131\n",
      "Processing batch 54/131\n",
      "Processing batch 55/131\n",
      "Processing batch 56/131\n",
      "Processing batch 57/131\n",
      "Processing batch 58/131\n",
      "Processing batch 59/131\n",
      "Processing batch 60/131\n",
      "Processing batch 61/131\n",
      "Processing batch 62/131\n",
      "Processing batch 63/131\n",
      "Processing batch 64/131\n",
      "Processing batch 65/131\n",
      "Processing batch 66/131\n",
      "Processing batch 67/131\n",
      "Processing batch 68/131\n",
      "Processing batch 69/131\n",
      "Processing batch 70/131\n",
      "Processing batch 71/131\n",
      "Processing batch 72/131\n",
      "Processing batch 73/131\n",
      "Processing batch 74/131\n",
      "Processing batch 75/131\n",
      "Processing batch 76/131\n",
      "Processing batch 77/131\n",
      "Processing batch 78/131\n",
      "Processing batch 79/131\n",
      "Processing batch 80/131\n",
      "Processing batch 81/131\n",
      "Processing batch 82/131\n",
      "Processing batch 83/131\n",
      "Processing batch 84/131\n",
      "Processing batch 85/131\n",
      "Processing batch 86/131\n",
      "Processing batch 87/131\n",
      "Processing batch 88/131\n",
      "Processing batch 89/131\n",
      "Processing batch 90/131\n",
      "Processing batch 91/131\n",
      "Processing batch 92/131\n",
      "Processing batch 93/131\n",
      "Processing batch 94/131\n",
      "Processing batch 95/131\n",
      "Processing batch 96/131\n",
      "Processing batch 97/131\n",
      "Processing batch 98/131\n",
      "Processing batch 99/131\n",
      "Processing batch 100/131\n",
      "Processing batch 101/131\n",
      "Processing batch 102/131\n",
      "Processing batch 103/131\n",
      "Processing batch 104/131\n",
      "Processing batch 105/131\n",
      "Processing batch 106/131\n",
      "Processing batch 107/131\n",
      "Processing batch 108/131\n",
      "Processing batch 109/131\n",
      "Processing batch 110/131\n",
      "Processing batch 111/131\n",
      "Processing batch 112/131\n",
      "Processing batch 113/131\n",
      "Processing batch 114/131\n",
      "Processing batch 115/131\n",
      "Processing batch 116/131\n",
      "Processing batch 117/131\n",
      "Processing batch 118/131\n",
      "Processing batch 119/131\n",
      "Processing batch 120/131\n",
      "Processing batch 121/131\n",
      "Processing batch 122/131\n",
      "Processing batch 123/131\n",
      "Processing batch 124/131\n",
      "Processing batch 125/131\n",
      "Processing batch 126/131\n",
      "Processing batch 127/131\n",
      "Processing batch 128/131\n",
      "Processing batch 129/131\n",
      "Processing batch 130/131\n",
      "Processing batch 131/131\n",
      "Submission file created at finetuned_submission.csv with 4163 predictions\n"
     ]
    }
   ],
   "source": [
    "# Function to generate predictions from a saved model\n",
    "def generate_predictions(model_path, output_filename):\n",
    "    print(f\"Generating predictions using model: {model_path}\")\n",
    "        \n",
    "        # Load the saved model\n",
    "    model = ProteinClassifier.load_from_checkpoint(model_path)\n",
    "    model.eval()\n",
    "    model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Load test data\n",
    "    test_df = pd.read_csv(f\"{data_root}/test_data.csv\")\n",
    "    sequences = test_df.loc[:, \"sequence\"].values\n",
    "        # Replace rare amino acids\n",
    "    sequences = [re.sub(r'[UBOZ]', 'X', seq) for seq in sequences]\n",
    "    sequence_names = test_df.loc[:, \"sequence_name\"].values\n",
    "        \n",
    "        # Process sequences in batches\n",
    "    batch_size = 32\n",
    "    predictions = []\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(sequences), batch_size):\n",
    "            print(f\"Processing batch {i//batch_size + 1}/{(len(sequences) + batch_size - 1)//batch_size}\")\n",
    "            batch_sequences = sequences[i:i+batch_size]\n",
    "            logits = model(batch_sequences)\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "                # Convert indices back to family_ids\n",
    "            pred_classes = [datamodule.classes[idx] for idx in preds]\n",
    "            predictions.extend(pred_classes)\n",
    "        \n",
    "        # Create submission file\n",
    "    submission_df = pd.DataFrame({\n",
    "        \"sequence_name\": sequence_names,\n",
    "        \"family_id\": predictions\n",
    "        })\n",
    "        \n",
    "    submission_df.to_csv(output_filename, index=False)\n",
    "    print(f\"Submission file created at {output_filename} with {len(submission_df)} predictions\")\n",
    "    \n",
    "    # Generate predictions for both models\n",
    "generate_predictions(baseline_checkpoint.best_model_path, \"baseline_submission.csv\")\n",
    "generate_predictions(finetuned_checkpoint.best_model_path, \"finetuned_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up ESM2 model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ESM2 model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | embedder       | EsmModel           | 34.0 M | eval \n",
      "1 | classifier     | Sequential         | 259 K  | train\n",
      "2 | criterion      | CrossEntropyLoss   | 0      | train\n",
      "3 | val_accuracy   | MulticlassAccuracy | 0      | train\n",
      "4 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "5 | val_f1         | MulticlassF1Score  | 0      | train\n",
      "--------------------------------------------------------------\n",
      "34.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "34.3 M    Total params\n",
      "137.008   Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "230       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anorm\\anaconda3\\envs\\crystal\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anorm\\anaconda3\\envs\\crystal\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/4163 [27:37<?, ?it/s]                  =3, train_acc=1.000]\n",
      "Epoch 0: 100%|██████████| 4163/4163 [3:28:31<00:00,  0.33it/s, v_num=3, train_acc=1.000, val_acc=1.000, val_f1=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1 improved. New best score: 1.000\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 4163/4163 [3:28:34<00:00,  0.33it/s, v_num=3, train_acc=1.000, val_acc=1.000, val_f1=1.000]\n",
      "ESM2 model saved at: C:\\Users\\Anorm\\Downloads\\models\\esm2\\esm2-epoch=00-val_f1=0.9995.ckpt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from lightning import LightningModule\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "import torchmetrics\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import os\n",
    "from lightning import Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import pandas as pd\n",
    "import re\n",
    "from datamodule import PAFDatamodule\n",
    "\n",
    "class ESM2Classifier(LightningModule):\n",
    "    def __init__(self, n_classes=25):\n",
    "        super().__init__()\n",
    "        self.model_name = \"facebook/esm2_t12_35M_UR50D\"  # Smaller ESM-2 model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.embedder = AutoModel.from_pretrained(self.model_name)\n",
    "        \n",
    "        # Get embedding dimension\n",
    "        embedding_dim = self.embedder.config.hidden_size\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, n_classes)\n",
    "        )\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.val_accuracy = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=n_classes)\n",
    "        self.train_accuracy = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=n_classes)\n",
    "        self.val_f1 = torchmetrics.classification.F1Score(task=\"multiclass\", num_classes=n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Tokenize sequences\n",
    "        encoding = self.tokenizer(x, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024)\n",
    "        input_ids = encoding['input_ids'].to(self.device)\n",
    "        attention_mask = encoding['attention_mask'].to(self.device)\n",
    "        \n",
    "        # Get sequence embeddings\n",
    "        outputs = self.embedder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Use CLS token representation\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # Pass through classification head\n",
    "        logits = self.classifier(embeddings)\n",
    "        return logits\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.train_accuracy(preds, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", self.train_accuracy, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_accuracy(preds, y)\n",
    "        self.val_f1(preds, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\", self.val_accuracy, prog_bar=True)\n",
    "        self.log(\"val_f1\", self.val_f1, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Use different learning rates for pretrained model and classifier\n",
    "        optimizer = AdamW([\n",
    "            {\"params\": self.embedder.parameters(), \"lr\": 1e-5},\n",
    "            {\"params\": self.classifier.parameters(), \"lr\": 5e-5}\n",
    "        ])\n",
    "        \n",
    "        # Add a learning rate scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=10, eta_min=1e-6\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"epoch\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set parameters\n",
    "    n_classes = 25\n",
    "    data_root = \"datafiles\"\n",
    "    \n",
    "    # Create directory for saving models\n",
    "    os.makedirs(\"models/esm2\", exist_ok=True)\n",
    "    \n",
    "    # Initialize data module\n",
    "    datamodule = PAFDatamodule(data_root, batch_size=8)  # Smaller batch for larger model\n",
    "    \n",
    "    # Initialize ESM2 model\n",
    "    print(\"Setting up ESM2 model...\")\n",
    "    esm2_model = ESM2Classifier(n_classes=n_classes)\n",
    "    \n",
    "    # Define callbacks\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        dirpath=\"models/esm2/\",\n",
    "        filename=\"esm2-{epoch:02d}-{val_f1:.4f}\",\n",
    "        monitor=\"val_f1\",\n",
    "        mode=\"max\",\n",
    "        save_top_k=1\n",
    "    )\n",
    "    \n",
    "    early_stop = EarlyStopping(\n",
    "        monitor=\"val_f1\",\n",
    "        patience=3,\n",
    "        verbose=True,\n",
    "        mode=\"max\"\n",
    "    )\n",
    "    \n",
    "    # Setup TensorBoard logger to log training metrics\n",
    "    logger = TensorBoardLogger(\"tb_logs\", name=\"esm2_classifier\")\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Training ESM2 model...\")\n",
    "    trainer = Trainer(\n",
    "        max_epochs=1,\n",
    "        callbacks=[checkpoint, early_stop],\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "        gradient_clip_val=1.0,\n",
    "        logger=logger  \n",
    "    )\n",
    "    \n",
    "    trainer.fit(model=esm2_model, datamodule=datamodule)\n",
    "    \n",
    "    # Save the final model\n",
    "    trainer.save_checkpoint(\"models/esm2/final_esm2_model.ckpt\")\n",
    "    \n",
    "    # Save best model path\n",
    "    with open(\"models/esm2/best_model_path.txt\", \"w\") as f:\n",
    "        f.write(checkpoint.best_model_path)\n",
    "    \n",
    "    print(f\"ESM2 model saved at: {checkpoint.best_model_path}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions using ESM2 model: C:\\Users\\Anorm\\Downloads\\models\\esm2\\esm2-epoch=00-val_f1=0.9995.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t12_35M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/261\n",
      "Processing batch 2/261\n",
      "Processing batch 3/261\n",
      "Processing batch 4/261\n",
      "Processing batch 5/261\n",
      "Processing batch 6/261\n",
      "Processing batch 7/261\n",
      "Processing batch 8/261\n",
      "Processing batch 9/261\n",
      "Processing batch 10/261\n",
      "Processing batch 11/261\n",
      "Processing batch 12/261\n",
      "Processing batch 13/261\n",
      "Processing batch 14/261\n",
      "Processing batch 15/261\n",
      "Processing batch 16/261\n",
      "Processing batch 17/261\n",
      "Processing batch 18/261\n",
      "Processing batch 19/261\n",
      "Processing batch 20/261\n",
      "Processing batch 21/261\n",
      "Processing batch 22/261\n",
      "Processing batch 23/261\n",
      "Processing batch 24/261\n",
      "Processing batch 25/261\n",
      "Processing batch 26/261\n",
      "Processing batch 27/261\n",
      "Processing batch 28/261\n",
      "Processing batch 29/261\n",
      "Processing batch 30/261\n",
      "Processing batch 31/261\n",
      "Processing batch 32/261\n",
      "Processing batch 33/261\n",
      "Processing batch 34/261\n",
      "Processing batch 35/261\n",
      "Processing batch 36/261\n",
      "Processing batch 37/261\n",
      "Processing batch 38/261\n",
      "Processing batch 39/261\n",
      "Processing batch 40/261\n",
      "Processing batch 41/261\n",
      "Processing batch 42/261\n",
      "Processing batch 43/261\n",
      "Processing batch 44/261\n",
      "Processing batch 45/261\n",
      "Processing batch 46/261\n",
      "Processing batch 47/261\n",
      "Processing batch 48/261\n",
      "Processing batch 49/261\n",
      "Processing batch 50/261\n",
      "Processing batch 51/261\n",
      "Processing batch 52/261\n",
      "Processing batch 53/261\n",
      "Processing batch 54/261\n",
      "Processing batch 55/261\n",
      "Processing batch 56/261\n",
      "Processing batch 57/261\n",
      "Processing batch 58/261\n",
      "Processing batch 59/261\n",
      "Processing batch 60/261\n",
      "Processing batch 61/261\n",
      "Processing batch 62/261\n",
      "Processing batch 63/261\n",
      "Processing batch 64/261\n",
      "Processing batch 65/261\n",
      "Processing batch 66/261\n",
      "Processing batch 67/261\n",
      "Processing batch 68/261\n",
      "Processing batch 69/261\n",
      "Processing batch 70/261\n",
      "Processing batch 71/261\n",
      "Processing batch 72/261\n",
      "Processing batch 73/261\n",
      "Processing batch 74/261\n",
      "Processing batch 75/261\n",
      "Processing batch 76/261\n",
      "Processing batch 77/261\n",
      "Processing batch 78/261\n",
      "Processing batch 79/261\n",
      "Processing batch 80/261\n",
      "Processing batch 81/261\n",
      "Processing batch 82/261\n",
      "Processing batch 83/261\n",
      "Processing batch 84/261\n",
      "Processing batch 85/261\n",
      "Processing batch 86/261\n",
      "Processing batch 87/261\n",
      "Processing batch 88/261\n",
      "Processing batch 89/261\n",
      "Processing batch 90/261\n",
      "Processing batch 91/261\n",
      "Processing batch 92/261\n",
      "Processing batch 93/261\n",
      "Processing batch 94/261\n",
      "Processing batch 95/261\n",
      "Processing batch 96/261\n",
      "Processing batch 97/261\n",
      "Processing batch 98/261\n",
      "Processing batch 99/261\n",
      "Processing batch 100/261\n",
      "Processing batch 101/261\n",
      "Processing batch 102/261\n",
      "Processing batch 103/261\n",
      "Processing batch 104/261\n",
      "Processing batch 105/261\n",
      "Processing batch 106/261\n",
      "Processing batch 107/261\n",
      "Processing batch 108/261\n",
      "Processing batch 109/261\n",
      "Processing batch 110/261\n",
      "Processing batch 111/261\n",
      "Processing batch 112/261\n",
      "Processing batch 113/261\n",
      "Processing batch 114/261\n",
      "Processing batch 115/261\n",
      "Processing batch 116/261\n",
      "Processing batch 117/261\n",
      "Processing batch 118/261\n",
      "Processing batch 119/261\n",
      "Processing batch 120/261\n",
      "Processing batch 121/261\n",
      "Processing batch 122/261\n",
      "Processing batch 123/261\n",
      "Processing batch 124/261\n",
      "Processing batch 125/261\n",
      "Processing batch 126/261\n",
      "Processing batch 127/261\n",
      "Processing batch 128/261\n",
      "Processing batch 129/261\n",
      "Processing batch 130/261\n",
      "Processing batch 131/261\n",
      "Processing batch 132/261\n",
      "Processing batch 133/261\n",
      "Processing batch 134/261\n",
      "Processing batch 135/261\n",
      "Processing batch 136/261\n",
      "Processing batch 137/261\n",
      "Processing batch 138/261\n",
      "Processing batch 139/261\n",
      "Processing batch 140/261\n",
      "Processing batch 141/261\n",
      "Processing batch 142/261\n",
      "Processing batch 143/261\n",
      "Processing batch 144/261\n",
      "Processing batch 145/261\n",
      "Processing batch 146/261\n",
      "Processing batch 147/261\n",
      "Processing batch 148/261\n",
      "Processing batch 149/261\n",
      "Processing batch 150/261\n",
      "Processing batch 151/261\n",
      "Processing batch 152/261\n",
      "Processing batch 153/261\n",
      "Processing batch 154/261\n",
      "Processing batch 155/261\n",
      "Processing batch 156/261\n",
      "Processing batch 157/261\n",
      "Processing batch 158/261\n",
      "Processing batch 159/261\n",
      "Processing batch 160/261\n",
      "Processing batch 161/261\n",
      "Processing batch 162/261\n",
      "Processing batch 163/261\n",
      "Processing batch 164/261\n",
      "Processing batch 165/261\n",
      "Processing batch 166/261\n",
      "Processing batch 167/261\n",
      "Processing batch 168/261\n",
      "Processing batch 169/261\n",
      "Processing batch 170/261\n",
      "Processing batch 171/261\n",
      "Processing batch 172/261\n",
      "Processing batch 173/261\n",
      "Processing batch 174/261\n",
      "Processing batch 175/261\n",
      "Processing batch 176/261\n",
      "Processing batch 177/261\n",
      "Processing batch 178/261\n",
      "Processing batch 179/261\n",
      "Processing batch 180/261\n",
      "Processing batch 181/261\n",
      "Processing batch 182/261\n",
      "Processing batch 183/261\n",
      "Processing batch 184/261\n",
      "Processing batch 185/261\n",
      "Processing batch 186/261\n",
      "Processing batch 187/261\n",
      "Processing batch 188/261\n",
      "Processing batch 189/261\n",
      "Processing batch 190/261\n",
      "Processing batch 191/261\n",
      "Processing batch 192/261\n",
      "Processing batch 193/261\n",
      "Processing batch 194/261\n",
      "Processing batch 195/261\n",
      "Processing batch 196/261\n",
      "Processing batch 197/261\n",
      "Processing batch 198/261\n",
      "Processing batch 199/261\n",
      "Processing batch 200/261\n",
      "Processing batch 201/261\n",
      "Processing batch 202/261\n",
      "Processing batch 203/261\n",
      "Processing batch 204/261\n",
      "Processing batch 205/261\n",
      "Processing batch 206/261\n",
      "Processing batch 207/261\n",
      "Processing batch 208/261\n",
      "Processing batch 209/261\n",
      "Processing batch 210/261\n",
      "Processing batch 211/261\n",
      "Processing batch 212/261\n",
      "Processing batch 213/261\n",
      "Processing batch 214/261\n",
      "Processing batch 215/261\n",
      "Processing batch 216/261\n",
      "Processing batch 217/261\n",
      "Processing batch 218/261\n",
      "Processing batch 219/261\n",
      "Processing batch 220/261\n",
      "Processing batch 221/261\n",
      "Processing batch 222/261\n",
      "Processing batch 223/261\n",
      "Processing batch 224/261\n",
      "Processing batch 225/261\n",
      "Processing batch 226/261\n",
      "Processing batch 227/261\n",
      "Processing batch 228/261\n",
      "Processing batch 229/261\n",
      "Processing batch 230/261\n",
      "Processing batch 231/261\n",
      "Processing batch 232/261\n",
      "Processing batch 233/261\n",
      "Processing batch 234/261\n",
      "Processing batch 235/261\n",
      "Processing batch 236/261\n",
      "Processing batch 237/261\n",
      "Processing batch 238/261\n",
      "Processing batch 239/261\n",
      "Processing batch 240/261\n",
      "Processing batch 241/261\n",
      "Processing batch 242/261\n",
      "Processing batch 243/261\n",
      "Processing batch 244/261\n",
      "Processing batch 245/261\n",
      "Processing batch 246/261\n",
      "Processing batch 247/261\n",
      "Processing batch 248/261\n",
      "Processing batch 249/261\n",
      "Processing batch 250/261\n",
      "Processing batch 251/261\n",
      "Processing batch 252/261\n",
      "Processing batch 253/261\n",
      "Processing batch 254/261\n",
      "Processing batch 255/261\n",
      "Processing batch 256/261\n",
      "Processing batch 257/261\n",
      "Processing batch 258/261\n",
      "Processing batch 259/261\n",
      "Processing batch 260/261\n",
      "Processing batch 261/261\n",
      "ESM2 submission file created at esm2_submission.csv with 4163 predictions\n"
     ]
    }
   ],
   "source": [
    "# Function to generate predictions from the ESM2 model\n",
    "def generate_esm2_predictions(model_path, output_filename):\n",
    "    print(f\"Generating predictions using ESM2 model: {model_path}\")\n",
    "        \n",
    "        # Load the saved model\n",
    "    model = ESM2Classifier.load_from_checkpoint(model_path)\n",
    "    model.eval()\n",
    "    model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Load test data\n",
    "    test_df = pd.read_csv(f\"{data_root}/test_data.csv\")\n",
    "    sequences = test_df.loc[:, \"sequence\"].values\n",
    "        # Replace rare amino acids\n",
    "    sequences = [re.sub(r'[UBOZ]', 'X', seq) for seq in sequences]\n",
    "    sequence_names = test_df.loc[:, \"sequence_name\"].values\n",
    "        \n",
    "        # Process sequences in batches\n",
    "    batch_size = 16  # Adjust batch size as needed\n",
    "    predictions = []\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(sequences), batch_size):\n",
    "            print(f\"Processing batch {i//batch_size + 1}/{(len(sequences) + batch_size - 1)//batch_size}\")\n",
    "            batch_sequences = sequences[i:i+batch_size]\n",
    "            logits = model(batch_sequences)\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "                # Convert indices back to family_ids\n",
    "            pred_classes = [datamodule.classes[idx] for idx in preds]\n",
    "            predictions.extend(pred_classes)\n",
    "        \n",
    "        # Create submission file\n",
    "    submission_df = pd.DataFrame({\n",
    "        \"sequence_name\": sequence_names,\n",
    "        \"family_id\": predictions\n",
    "        })\n",
    "        \n",
    "    submission_df.to_csv(output_filename, index=False)\n",
    "    print(f\"ESM2 submission file created at {output_filename} with {len(submission_df)} predictions\")\n",
    "    \n",
    "    # Generate predictions\n",
    "generate_esm2_predictions(checkpoint.best_model_path, \"esm2_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "import umap.umap_ as umap\n",
    "from sklearn.manifold import TSNE\n",
    "import pickle\n",
    "import re\n",
    "import sys\n",
    "sys.argv = [sys.argv[0]]  # Clear any arguments passed to IPython\n",
    "\n",
    "def extract_embeddings(model, sequences, batch_size=8):\n",
    "    \"\"\"Extract embeddings for visualization\"\"\"\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(sequences), batch_size):\n",
    "            batch_sequences = sequences[i:i+batch_size]\n",
    "            # Get embeddings depending on model type\n",
    "            if hasattr(model, 'embedder') and model.embedder.__class__.__name__ == 'BertGenerationEncoder':\n",
    "                # ProtBERT model\n",
    "                lengths = torch.tensor([len(seq) for seq in batch_sequences]).to(model.device)\n",
    "                ids = model.tokenizer(batch_sequences, add_special_tokens=True, padding=\"longest\")\n",
    "                input_ids = torch.tensor(ids['input_ids']).to(model.device)\n",
    "                attention_mask = torch.tensor(ids['attention_mask']).to(model.device)\n",
    "                \n",
    "                outputs = model.embedder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                batch_embeddings = outputs.last_hidden_state.sum(dim=1)/lengths.view(-1, 1)\n",
    "            else:\n",
    "                # ESM2 model\n",
    "                encoding = model.tokenizer(batch_sequences, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "                input_ids = encoding['input_ids'].to(model.device)\n",
    "                attention_mask = encoding['attention_mask'].to(model.device)\n",
    "                \n",
    "                outputs = model.embedder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                batch_embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "            \n",
    "            embeddings.append(batch_embeddings.cpu().numpy())\n",
    "    \n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "def visualize_embeddings(model_path, output_prefix, data_root=\"datafiles\"):\n",
    "    \"\"\"Create UMAP and t-SNE visualizations of protein embeddings\"\"\"\n",
    "    print(f\"Generating visualizations for model: {model_path}\")\n",
    "    \n",
    "    # Determine model type and load it\n",
    "    if \"esm2\" in model_path:\n",
    "        from esm2_model import ESM2Classifier\n",
    "        model = ESM2Classifier.load_from_checkpoint(model_path)\n",
    "    else:\n",
    "        from prot_bert import ProteinClassifier\n",
    "        model = ProteinClassifier.load_from_checkpoint(model_path)\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load validation data (with known labels) for visualization\n",
    "    val_df = pd.read_csv(f\"{data_root}/val_data.csv\")\n",
    "    sequences = val_df.loc[:, \"sequence\"].values\n",
    "    # Replace rare amino acids\n",
    "    sequences = [re.sub(r'[UBOZ]', 'X', seq) for seq in sequences]\n",
    "    \n",
    "    # Get family_ids and map to indices\n",
    "    family_ids = val_df.loc[:, \"family_id\"].values\n",
    "    classes = pickle.load(open(f\"{data_root}/selected_families.pkl\", \"rb\"))\n",
    "    cls2idx = dict(zip(classes, range(len(classes))))\n",
    "    labels = np.array([cls2idx[fam] for fam in family_ids])\n",
    "    \n",
    "    # Limit to 1000 sequences for faster visualization\n",
    "    if len(sequences) > 1000:\n",
    "        indices = np.random.choice(len(sequences), 1000, replace=False)\n",
    "        sequences = [sequences[i] for i in indices]\n",
    "        labels = labels[indices]\n",
    "    \n",
    "    # Extract embeddings\n",
    "    print(\"Extracting embeddings...\")\n",
    "    embeddings = extract_embeddings(model, sequences)\n",
    "    \n",
    "    # UMAP visualization\n",
    "    print(\"Generating UMAP visualization...\")\n",
    "    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "    umap_embeddings = reducer.fit_transform(embeddings)\n",
    "    \n",
    "    # Plot UMAP\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    unique_labels = np.unique(labels)\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(unique_labels)))\n",
    "    \n",
    "    for i, label in enumerate(unique_labels):\n",
    "        idx = labels == label\n",
    "        plt.scatter(umap_embeddings[idx, 0], umap_embeddings[idx, 1], \n",
    "                   c=[colors[i]], label=classes[label], alpha=0.7, s=10)\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.title('UMAP projection of protein embeddings')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_prefix}_umap.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # t-SNE visualization\n",
    "    print(\"Generating t-SNE visualization...\")\n",
    "    tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=42)\n",
    "    tsne_embeddings = tsne.fit_transform(embeddings)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        idx = labels == label\n",
    "        plt.scatter(tsne_embeddings[idx, 0], tsne_embeddings[idx, 1], \n",
    "                   c=[colors[i]], label=classes[label], alpha=0.7, s=10)\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.title('t-SNE projection of protein embeddings')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_prefix}_tsne.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    print(f\"Visualizations saved as {output_prefix}_umap.png and {output_prefix}_tsne.png\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description=\"Visualize protein embeddings\")\n",
    "    parser.add_argument(\"--model\", type=str, help=\"Path to the saved model checkpoint\")\n",
    "    parser.add_argument(\"--output\", type=str, default=\"embeddings\", help=\"Output filename prefix\")\n",
    "    parser.add_argument(\"--data\", type=str, default=\"datafiles\", help=\"Path to data directory\")\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # If no model path is provided, try to read from the best model path files\n",
    "    if args.model is None:\n",
    "        model_paths = []\n",
    "        for model_type in [\"baseline\", \"finetuned\", \"esm2\"]:\n",
    "            try:\n",
    "                with open(f\"models/{model_type}/best_model_path.txt\", \"r\") as f:\n",
    "                    model_paths.append((f.read().strip(), f\"{args.output}_{model_type}\"))\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Could not find best_model_path.txt for {model_type} model.\")\n",
    "        \n",
    "        if not model_paths:\n",
    "            print(\"No model paths found. Please specify a model path.\")\n",
    "            exit(1)\n",
    "        \n",
    "        # Visualize all available models\n",
    "        for model_path, output_prefix in model_paths:\n",
    "            visualize_embeddings(model_path, output_prefix, args.data)\n",
    "    else:\n",
    "        # Visualize the specified model\n",
    "        visualize_embeddings(args.model, args.output, args.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crystal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
